\subsection{Le théorème CAP}
	Classiquement, la focalisation de l'informatique distribuée était faite sur le calcul, et non sur les données. C'est pour des besoins de calcul qu'on créait des clusters, pour atteindre une puissance de calcul multipliée par le nombre de nœuds. Eric Brewer, professeur de l'université de Californie affirme que le calcul distribué est relativement facile. Le paradigme MapReduce abordé dans la partie~\ref{subsec:principeMapReduce} est maintenant éprouvé et n'est plus particulièrement difficilement à mettre en place. Ce qui est difficile, c'est la distribution des données. Le professeur Brewer énonce le théorème CAP, une abréviation de trois propriétés :
	\vspace{10px}
	\begin{itemize}
		\item \textbf{\textit{Consistency}} (cohérence) : tous les nœuds sont à jour sur les données au même moment ; 
		\item \textbf{\textit{Availability}} (disponibilité) : la perte d'un nœud n'empêche pas le système de fonctionner et de servir l'intégralité des données ; 
		\item \textbf{\textit{Partition tolerance}} (résistance au morcellement) : chaque nœud doit pouvoir fonctionner de manière autonome. 
	\end{itemize}
	\vspace{20px}
	L'expression \textit{Partition tolerance} n'est pas très claire. On entend par là qu'un système partitionné doit pouvoir survivre aux difficultés du réseau. D'après Seth Gilbert\footnote{Seth Gilbert est un doctorant à l'École polytechnique fédérale de Lausanne (EPFL).} et Nancy Lynch\footnote{Nancy Lynch est une professeure au Massachusetts Institute of Technology (MIT).}, \enquote{le système doit être capable de survivre aux aléas de la perte de partitions ou de communication entre les partitions. Il ne s'agit pas d'une garantie totale d'accès à partir d'un nœud, mais bien d'une capacité à la survie et à la résilience aussi poussée que possible.}\\

	Les bases de données distribuées ne peuvent satisfaire que deux de ces critères au plus.

\subsection{La dénormalisation des données}
	Dans une relation entre deux schémas A et B, la dénormalisation consiste à dupliquer certaines données de la table B dans la table A, dans un souci d'optimisation des requêtes. On pourra alors se contenter d'interroger la table A sans avoir à faire une jointure entre A et B.\\

	Les bases de données NoSQL utilisent parfois ce principe lors de la modélisation de la base. Dans une modélisation relationnelle, ceci était totalement prohibé par les formes normales.

\subsection{La gestion de la redondance des données}
	Nous avons vu ce qu'était le principe de dénormalisation. L'absence de relation entre tables induit un volume de données beaucoup plus grand car les informations sont parfois stockées de façon redondante pour être accessible plus facilement. Il est bien sûr possible de simuler des relations entre les enregistrements.\\

	Les exemples utilisés dans cette partie sont des documents structurés au format JSON. De tels documents peuvent être stockés dans une base de données NoSQL orientée document, comme abordé dans la partie~\ref{sec:BDDDocuments}.

	\subsubsection{Imbrication d'enregistrements}
		Pour une relation entre deux enregistrements A et B, cela consiste à avoir l'enregistrement B imbriqué dans l'enregistrement A. On peut avoir deux cas d'utilisation lorsque l'on utilise cette stratégie :

		\begin{itemize}
			\item On peut se passer de la collection des enregistrements imbriqués. Ainsi, toutes les requêtes concernant l'enregistrement parent concerneront aussi les données de l'enregistrement imbriqué.
			\item On peut modifier les enregistrements parents et enfants d'une manière atomique. Cependant, l'imbrication d'enregistrements n'est pas possible si on veut créer l'enregistrement enfant avant l'enregistrement parent.
		\end{itemize}
		\vspace{20px}

		\begin{listing}[H]
			\inputminted{json}{code/imbrication.json}
			\caption{Imbrication de l'adresse dans l'enregistrement d'un client.}
		\end{listing}

	\subsubsection{Duplication d'un sous-ensemble de champs}
		L'idée est de dupliquer le minimum de données de l'enregistrement B dans l'enregistrement A et de préférence celles qui ne changent pas souvent. En effet lors de la mise à jour nous devrions mettre à jour l'ensemble des enregistrements qui contiennent cette information plutôt qu'à un seul endroit dans une base de données respectant les formes normales. Il faut se souvenir que cette modélisation augmente donc le temps d'écriture lors d'une mise à jour.\\

		Par exemple, quand on affiche une liste d'articles, on a besoin que d'informations sommaires sur l'auteur de l'article : son nom et son avatar par exemple. C'est seulement en visitant le profil de l'auteur de l'article que l'on accédera aux informations complètes sur l'auteur de l'article.

		\begin{listing}[H]
			\inputminted{json}{code/duplicationSousEnsemble.json}
			\caption{Imbrication d'un sous-ensemble des champs d'un utilisateur sur l'enregistrement d'un article.}
		\end{listing}

	\subsubsection{Duplication de la clé-primaire}
		Cette fois, on ne duplique que la clé primaire de l'enregistrement B dans l'enregistrement A. pour récupérer les données on devra alors effectuer deux requêtes : une première requête pour récupérer les données de l'enregistrement A, puis une seconde pour récupérer les données de l'autre côté de la relation à l'aide des informations de l'enregistrement A.\\

		Par exemple, imaginons que l'on modélise une relation plusieurs vers plusieurs entre des livres et des auteurs. L'enregistrement de l'auteur contiendrait la liste des clés primaires de ses livres et le livre contiendrait les clés primaires de ses auteurs. On commencerait par récupérer les identifiants des auteurs puis on interrogerait les livres pour récupérer le reste des données.

		\begin{listing}[H]
			\inputminted{json}{code/duplicationClesPrimairesLivres.json}
			\caption{Imbrication des clés primaires des livres écrits par un écrivain.}
		\end{listing}