Depuis que les données sont réparties sur plusieurs centaines de machines, il a été nécessaire de trouver des moyens de répartir les calculs dans le cluster\footnote{En calcul distribué, le cluster est un système informatique composé d'unités de calcul (micro-processeurs, cœurs, unités centrales) autonomes qui sont reliées entre elles à l'aide d'un réseau de communication.\cite{Wikipedia_cluster}} et d'agréger les résultats de ces calculs pour produire une réponse finale. MapReduce est un principe et un algorithme utilisé pour ces besoins.

\subsection{Scalabilité horizontale}
	La scalabilité verticable désigne la possibilité d'augmenter les performances d'un serveur (ajout de processeurs, RAM, disques\dots) tandis que la scalabilité horizontale désigne la possibilité d'ajouter des serveurs d'un type donné.\cite{Wikipedia_scalabilite}. Ces dernières années, la diminution du coût du matériel a été une formidable opportunité pour cette dernière qui devient alors beaucoup plus intéressante.\\

	Optimiser les performances d'un SGBD\footnote{SGBD : Système de Gestion de Bases de Données} sur une seule machine demande beaucoup d'énergie et de compétences pour aboutir à des résultats fragiles et qui ne peuvent supporter une multiplication soudaine de la demande. En revanche, s'assurer que le modèle de traitement de données est bien distribué de la façon la plus élégante possible sur des machines séparées est beaucoup plus simple. En effet, l'achat et l'installation rapide de nouvelles machines (puissantes ou non) permettent de répondre à des augmentations éclairs de la demande. Ce processus est théoriquement répétable à l'infini afin de combler tous les besoins, il suffit uniquement de s'assurer que la défaillance d'une machine ne se traduise pas par une perte de données.\\

	Il faut donc vérifier que le modèle déployé est capable de distribuer au mieux les données et le travail, même sur plusieurs milliers de nœuds, en offrant un système de réplication suffisant pour éliminer statistiquement le risque de perte de données.

\subsection{Pourquoi MapReduce ?}
	Comment traiter des volumes gigantesques de données, réparti sur plusieurs machines dans plusieurs centres de données pour en tirer des résultats de calculs, d'agrégats, de résumés\dots ? MapReduce a été défini par Google pour répondre à ces besoins.

\subsection{Principe de MapReduce}
	MapReduce a été défini en 2004 dans un brevet de Google.\cite{google_mapreduce}. Le principe est simple : pour distribuer un traitement, Google a imaginé une opération en deux étapes :
	\begin{enumerate}
		\item L'attribution des opérations à effectuer sur chaque machine (étape \texttt{Map}) ;
		\item Rassemblement des résultats après l'étape de traitement (étape \texttt{Reduce}).
	\end{enumerate}

	En soi, le raisonnement n'est pas révolutionnaire et n'a pas été inventé par Google. Les opérations de \texttt{map} et de \texttt{reduce} ont été inspirées par les primitives du même nom en Lisp. Le brevet de Google répond néanmoins aux problématiques de MapReduce dans un environnement distribué. Que faire en cas de défaillance d'une unité de traitement ? Comment s'assurer d'une bonne distribution du travail ? Comment synchroniser les résultats des traitements ?

\subsection{Hadoop, une implémentation de MapReduce}
	L'implémentation la plus connue de MapReduce est le framework Java libre Hadoop. Hadoop utilise totalement le principe de la scalabilité horizontale puisque Hadoop a été conçu pour fonctionner avec plusieurs milliers de machines au sein d'un même cluster.\\

	Hadoop a été créé par Doug Cutting qui s'est inspiré du GoogleFS\footnote{GoogleFS : \textit{Google File System}. Google File System (GFS) est un système de fichiers distribué propriétaire. Il est développé par Google pour leurs propres applications.}. Hadoop utilise le HDFS\footnote{HDFS : \textit{Hadoop Distributed File System.}}, système de fichiers distribué extensible. Il a été conçu pour stocker de très gros volumes de données sur un grand nombre de machines. Aujourd'hui le plus gros cluster Hadoop est exploité par Yahoo : celui-ci compte 10 000 machines.\cite{yahoo_hadoop} Facebook utilise également Hadoop et stocke plus de 100 000 téraoctets sur son cluster.\cite{facebook_hadoop}
