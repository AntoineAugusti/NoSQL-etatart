\epigraph{``Big Data is like teenage sex: everyone talks about it, nobody really knows how to do it, everyone thinks everyone else is doing, so everyone claims they are doing it."}{\textup{\symbol{64}achille\_z}, Twitter}

Aux débuts des années 2000, avec la généralisation des interconnexions de réseaux, l'augmentation de la bande passante sur Internet et la diminution des coûts des machines moyennement puissantes, de nouvelles possibilités ont vu le jour dans le domaine de l'informatique distribuée\footnote{L’architecture d'un environnement informatique ou d'un réseau est dite distribuée quand toutes les ressources ne se trouvent pas au même endroit ou sur la même machine.\cite{Wikipedia_architecture_distribuee}} et de la virtualisation par exemple.\\

Le volume de données manipulées par certaines entreprises, notamment celles en rapport avec Internet a augmenté considérablement. Il était alors utopique de songer à stocker ces données sur une seule machine, celle-ci ne pouvant être suffisamment puissante pour pouvoir gérer une telle quantité d'information. L'informatisation croissante des traitements implique une multiplication exponentielle du volume de données qui se compte maintenant en pétaoctets (1 000 téraoctets)\footnote{En juin 2012 Facebook annonçait que son installation de Hadoop atteignait le volume physique de 100 pétaoctets.\cite{facebook_hadoop}}.\\

Les Anglo-Saxons ont nommé ce phénomène le \textit{Big Data}. La gestion et le traitement de ces volumes de données sont considérés comme un nouveau défi de l'informatique. Les moteurs de bases de données relationnels traditionnels, hautement transactionnels semblent dépassés par ces nouvelles contraintes.
